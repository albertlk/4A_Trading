{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/Kris/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import datetime, timedelta, date\n",
    "from dateutil.parser import parse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Alpaca API imports\n",
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "#Twitter API imports\n",
    "import tweepy as tw\n",
    "\n",
    "# NLP & Sentiment imports\n",
    "import re\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download/Update the VADER Lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter Authentication Verified\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "\"\"\"\n",
    "    Authenticates the Alpaca API and Twitter\n",
    "    Returns a pass/fail statement\n",
    "\"\"\"\n",
    "############################################################  \n",
    "    \n",
    "# Setting twitter access and api keys\n",
    "bearer_token = os.getenv(\"TWITTER_BEARER_TOKEN\")\n",
    "consumer_key= os.getenv(\"TWITTER_API_KEY\")\n",
    "consumer_secret= os.getenv(\"TWITTER_SECRET_KEY\")\n",
    "access_token= os.getenv(\"TWITTER_ACCESS_TOKEN\")\n",
    "access_token_secret= os.getenv(\"TWITTER_ACCESS_TOKEN_SECRET\")\n",
    "\n",
    "# authentication for twitter\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "twitter_api = tw.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "# test authentication\n",
    "try:\n",
    "    twitter_api.verify_credentials()\n",
    "    auth = \"Twitter Authentication Verified\"\n",
    "except:\n",
    "    auth = \"Error During Twitter Authentication\"\n",
    "    \n",
    "print(auth)\n",
    "\n",
    "# Set Alpaca API key and secret\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "alpaca_api = tradeapi.REST(alpaca_api_key, alpaca_secret_key, api_version='v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "\"\"\"\n",
    "    Sentiment calculation based on compound score\n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "def get_normalized(score):\n",
    "    \"\"\"\n",
    "    Calculates the sentiment based on the compound score.\n",
    "    \"\"\"\n",
    "    result = 0  # Neutral by default\n",
    "    if score >= 0.04:  # Positive\n",
    "        result = 1\n",
    "    elif score <= -0.04:  # Negative\n",
    "        result = -1\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "############################################################\n",
    "\"\"\"\n",
    "    Function that pulls stock data from a given ticker and timeframe.\n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "def daily_returns(ticker, timeframe):\n",
    "        \n",
    "    # Set current date and the date from one month ago using the ISO format\n",
    "    current_date = pd.Timestamp.now(tz=\"America/New_York\").isoformat()\n",
    "    past_date = pd.Timestamp(\"2021-01-01 00:00\", tz=\"America/New_York\").isoformat()\n",
    "\n",
    "    # Get stock data\n",
    "    df = alpaca_api.get_barset(\n",
    "        ticker,\n",
    "        timeframe,\n",
    "        limit=None,\n",
    "        start=past_date,\n",
    "        end=current_date,\n",
    "        after=None,\n",
    "        until=None,\n",
    "    ).df\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "############################################################\n",
    "\"\"\"\n",
    "    get_ticker_data(ticker):\n",
    "    Takes 1 argument, ticker to search tweets for.\n",
    "    \n",
    "    Scrapes Twitter for given search words.\n",
    "    Calculates compound sentiment with VADER sentiment analyzer \n",
    "    Normalizes VADER compound score\n",
    "    Returns Average Daily Sentiment Dataframe with Columns: \n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "def get_ticker_data(ticker):\n",
    "    \n",
    "    # alpaca api variables\n",
    "    ticker = ticker\n",
    "    timeframe = \"15Min\"\n",
    "\n",
    "    # call the alpaca api and return a dataframe of daily returns\n",
    "    daily_df = daily_returns(ticker, timeframe)\n",
    "\n",
    "    # Drop Outer Table Level and drop extra columns\n",
    "    daily_df = daily_df.droplevel(axis=1, level=0)\n",
    "    daily_df = daily_df.drop(columns=[\"open\", \"high\", \"low\", \"volume\"])\n",
    "\n",
    "    # Get the percent change of the closing prices, drop any NA rows, and reset the index\n",
    "    daily_df[\"percent_change\"] = daily_df.pct_change().dropna()\n",
    "\n",
    "\n",
    "    # Grouping the tweets by Hour and taking their average Hourly sentiment\n",
    "    avg_returns = daily_df.groupby(pd.Grouper(level=0, freq='H')).mean().dropna()\n",
    "    \n",
    "    return daily_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################################\n",
    "\"\"\"\n",
    "    Twitter: Scrape Tweets and Analyze Sentiment\n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "def twitter_sentiment(search_words, date_since, items):\n",
    "       \n",
    "    # Initialize the VADER sentiment analyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # initializing the tweets dataframe\n",
    "    df = []\n",
    "    \n",
    "    # adding retweet filter to search words\n",
    "    search_words = search_words + \" -filter:retweets\"\n",
    "    \n",
    "    # Fetch top tweets/hastags for given ticker\n",
    "    tweets = tw.Cursor(twitter_api.search,\n",
    "              q=search_words,\n",
    "              lang=\"en\",\n",
    "              since=date_since\n",
    "                    ).items(items)\n",
    "    \n",
    "    for tweet in tweets:\n",
    "    \n",
    "        #storing tweet text\n",
    "        tweet_fetched = tweet.text \n",
    "\n",
    "        # Get date of tweet\n",
    "        tweet_date = pd.Timestamp(tweet.created_at, tz=\"America/New_York\").isoformat()\n",
    "        \n",
    "        try:\n",
    "            sentiment = analyzer.polarity_scores(tweet_fetched)\n",
    "            compound = sentiment[\"compound\"]\n",
    "            #pos = sentiment[\"pos\"]\n",
    "            #neu = sentiment[\"neu\"]\n",
    "            #neg = sentiment[\"neg\"]\n",
    "        \n",
    "            df.append({\n",
    "                \"date\": tweet_date,\n",
    "                \"tweet\": tweet_fetched,\n",
    "                \"compound\": compound,\n",
    "                #\"positive\": pos,\n",
    "                #\"negative\": neg,\n",
    "                #\"neutral\": neu\n",
    "            \n",
    "            })\n",
    "        \n",
    "        except AttributeError:\n",
    "            pass\n",
    "    \n",
    "    df = pd.DataFrame(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "############################################################\n",
    "\"\"\"\n",
    "    get_twitter_sentiment(search_words):\n",
    "    Takes 2 argument, word(s) to search tweets for, and number of items (tweets) to return.\n",
    "    \n",
    "    Scrapes Twitter for given search words in tweet\n",
    "    Calculates compound sentiment with VADER sentiment analyzer on each tweet\n",
    "    Calculates average compound sentiment score each 1 hour\n",
    "    Normalizes average hourly VADER compound score\n",
    "    Returns Average Hourly Sentiment Dataframe with Columns: \n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "def get_avg_sentiment(search_words):\n",
    "\n",
    "    # tweepy variables\n",
    "    search_words = search_words\n",
    "    date_since = \"2021-01-01\"\n",
    "    items = 1000\n",
    "\n",
    "    # call the twitter sentiment function and return a dataframe\n",
    "    tweets_df = twitter_sentiment(search_words, date_since, items)\n",
    "\n",
    "    # Changes the date column to proper datetime format\n",
    "    tweets_df['date'] = pd.to_datetime(tweets_df['date'])\n",
    "    \n",
    "    # Grouping the tweets by Hour and taking their average Hourly sentiment\n",
    "    avg_hourly_sentiment = tweets_df.groupby(pd.Grouper(key='date', freq='H')).mean().dropna()\n",
    "    \n",
    "    # Get the normalized sentiment score of -1, 0, 1\n",
    "    avg_hourly_sentiment[\"normalized\"] = avg_hourly_sentiment[\"compound\"].apply(lambda x : get_normalized(x))\n",
    "    \n",
    "    return avg_hourly_sentiment\n",
    "\n",
    "\n",
    "############################################################\n",
    "\"\"\"\n",
    "    combine_sentiment_with_close(avg_hourly_returns, avg_hourly_sentiment):\n",
    "    Takes 2 arguments: the two dataframes to combine\n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "def combine_sentiment_with_close(avg_hourly_sentiment, avg_hourly_returns):\n",
    "\n",
    "    # Combines the average hourly Twitter sentiment dataframe with the hourly percent change dataframe\n",
    "    combined_df = avg_hourly_returns.join(avg_hourly_sentiment).dropna()#(how=\"any\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "\n",
    "############################################################\n",
    "\"\"\"\n",
    "    Machine Learning Model\n",
    "    Input the Sentiment data and return predicted stock returns\n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "def get_predictions(sentiment_df):\n",
    "\n",
    "\n",
    "    return predicted_df\n",
    "\n",
    "\n",
    "\n",
    "############################################################\n",
    "\"\"\"\n",
    "    main_function:\n",
    "    Defines the main function.\n",
    "    1 argument: search word to search twitter and stock prices.\n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "def main_function(twitter_search_word, ticker):\n",
    "      \n",
    "    twitter_sentiment = get_avg_sentiment(twitter_search_word)\n",
    "    percent_change = get_ticker_data(ticker)\n",
    "    combined_df = combine_sentiment_with_close(twitter_sentiment, percent_change) \n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>percent_change</th>\n",
       "      <th>compound</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [close, percent_change, compound, normalized]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_search_word = \"microsoft\" #search_word\n",
    "ticker = \"MSFT\" #ticker\n",
    "\n",
    "combined_df = main_function(twitter_search_word, ticker)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the sentiment ML model\n",
    "\n",
    "\n",
    "# feed the twitter data into the model\n",
    "\n",
    "\n",
    "# output predicted returns to df\n",
    "\n",
    "\n",
    "# return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
